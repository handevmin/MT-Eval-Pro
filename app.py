import streamlit as st
import pandas as pd
import os
import json
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from evaluation_engine import EvaluationEngine
from visualization import VisualizationGenerator
from config import Config
import tempfile
import zipfile

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="MT-Eval Pro",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

class MTEvalProApp:
    """MT-Eval Pro Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self):
        self.config = Config()
        self.visualizer = VisualizationGenerator()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'evaluation_results' not in st.session_state:
            st.session_state.evaluation_results = None
        if 'evaluation_engine' not in st.session_state:
            st.session_state.evaluation_engine = None
    
    def main(self):
        """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        
        # ì œëª©ê³¼ ì„¤ëª…
        st.title("MT-Eval Pro")
        st.markdown("**ê¸°ê³„ ë²ˆì—­ í’ˆì§ˆ ìë™ í‰ê°€ ì‹œìŠ¤í…œ**")
        st.markdown("---")
        
        # ë©”ì¸ ì»¨í…ì¸ 
        tab1, tab2, tab3 = st.tabs(["í‰ê°€ ì‹¤í–‰", "ìƒì„¸ ê²°ê³¼", "ë©”íŠ¸ë¦­ ì„¤ì •"])
        
        with tab1:
            self.evaluation_tab()
        
        with tab2:
            self.detailed_results_tab()
        
        with tab3:
            self.metrics_settings_tab()
    def evaluation_tab(self):
        """í‰ê°€ ì‹¤í–‰ íƒ­"""
        st.header("MT-Eval Pro: ê¸°ê³„ ë²ˆì—­ í’ˆì§ˆ í‰ê°€")
        st.markdown("ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ë²ˆì—­ í’ˆì§ˆ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
        
        # ë‹¨ê³„ë³„ UI
        st.markdown("---")
        
        # 1ë‹¨ê³„: API í‚¤ ì„¤ì •
        st.markdown("### 1ë‹¨ê³„: OpenAI API í‚¤ ì„¤ì •")
        st.markdown("GPT-4ë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ í‰ê°€ë¥¼ ìœ„í•´ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        api_key = st.text_input(
            "API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", 
            type="password",
            placeholder="sk-...",
            help="OpenAI ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        )
        
        if api_key:
            try:
                st.session_state.evaluation_engine = EvaluationEngine(api_key)
                st.success("API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"API í‚¤ ì˜¤ë¥˜: {e}")
                return
        else:
            st.warning("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        st.markdown("---")
        
        # 2ë‹¨ê³„: ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
        st.markdown("### 2ë‹¨ê³„: ë°ì´í„° íŒŒì¼ ì„ íƒ")
        st.markdown("í‰ê°€ì— ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
        
        file_option = st.radio(
            "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            ["ê¸°ë³¸ íŒŒì¼ ì‚¬ìš© (ìƒ˜í”Œ ë°ì´í„°)", "ë‚´ íŒŒì¼ ì—…ë¡œë“œ"],
            help="ê¸°ë³¸ íŒŒì¼: ì‹œìŠ¤í…œì— í¬í•¨ëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\në‚´ íŒŒì¼ ì—…ë¡œë“œ: ì§ì ‘ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤."
        )
        
        if file_option == "ë‚´ íŒŒì¼ ì—…ë¡œë“œ":
            uploaded_file = st.file_uploader(
                "Excel íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:",
                type=['xlsx', 'xls'],
                help="ì†ŒìŠ¤ í…ìŠ¤íŠ¸ì™€ ë²ˆì—­ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ í¬í•¨ëœ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
            )
            
            if uploaded_file:
                st.session_state.translation_file = uploaded_file
                st.success(f"íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {uploaded_file.name}")
            else:
                st.info("Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return
        else:
            st.info("ê¸°ë³¸ ìƒ˜í”Œ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©ì‹œ ì„¸ì…˜ ìƒíƒœì—ì„œ ì œê±°
            if 'translation_file' in st.session_state:
                del st.session_state.translation_file
        
        st.markdown("---")
        
        # 3ë‹¨ê³„: ì»¬ëŸ¼ ì„ íƒ
        st.markdown("### 3ë‹¨ê³„: ì»¬ëŸ¼ ì„ íƒ")
        st.markdown("Excel íŒŒì¼ì—ì„œ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ì™€ ë²ˆì—­ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.")
        
        # ë°ì´í„° ë¡œë“œí•˜ì—¬ ì»¬ëŸ¼ ì •ë³´ ì–»ê¸°
        try:
            from data_processor import DataProcessor
            processor = DataProcessor()
            
            translation_file = None
            if file_option == "ë‚´ íŒŒì¼ ì—…ë¡œë“œ" and 'translation_file' in st.session_state:
                import tempfile
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                    tmp.write(st.session_state.translation_file.getbuffer())
                    translation_file = tmp.name
            
            df = processor.load_translation_data(translation_file)
            if not df.empty:
                column_info = processor.get_available_columns(df)
                
                # ì»¬ëŸ¼ ì„ íƒì„ 2ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**A. ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ (ì›ë¬¸)**")
                    source_column = st.selectbox(
                        "ì˜ì–´ ì›ë¬¸ì´ í¬í•¨ëœ ì»¬ëŸ¼:",
                        options=column_info['text_columns'],
                        index=0 if column_info['source_candidates'] else 0,
                        help="ë²ˆì—­ì˜ ê¸°ì¤€ì´ ë˜ëŠ” ì˜ì–´ ì›ë¬¸ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”."
                    )
                
                with col2:
                    st.markdown("**B. ë²ˆì—­ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ (ë²ˆì—­ë¬¸)**")
                    # íƒ€ê²Ÿ ì»¬ëŸ¼ë“¤ê³¼ ìë™ ê°ì§€ëœ ì–¸ì–´ ì •ë³´
                    target_columns_info = processor.get_target_columns_with_languages(df)
                    available_targets = [info for info in target_columns_info if info['column_name'] != source_column]
                    
                    if available_targets:
                        selected_target_info = st.selectbox(
                            "ë²ˆì—­ëœ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì»¬ëŸ¼:",
                            options=available_targets,
                            format_func=lambda x: x['display_name'],
                            help="í‰ê°€í•  ë²ˆì—­ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”."
                        )
                
                if available_targets:
                    # ì–¸ì–´ ì •ë³´ í‘œì‹œ
                    st.markdown("**C. ì–¸ì–´ í™•ì¸**")
                    col3, col4 = st.columns([2, 1])
                    
                    with col3:
                        st.success(f"ê°ì§€ëœ ì–¸ì–´: **{selected_target_info['language_name']}** ({selected_target_info['language_code']})")
                    
                    with col4:
                        # ì–¸ì–´ ìˆ˜ë™ ë³€ê²½ ì˜µì…˜
                        if st.button("ì–¸ì–´ ë³€ê²½", type="secondary"):
                            st.session_state.show_language_selector = True
                    
                    # ì–¸ì–´ ìˆ˜ë™ ì„ íƒ
                    if st.session_state.get('show_language_selector', False):
                        st.markdown("**ì–¸ì–´ ìˆ˜ë™ ì„ íƒ:**")
                        manual_language = st.selectbox(
                            "ì˜¬ë°”ë¥¸ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                            options=list(self.config.SUPPORTED_LANGUAGES.keys()),
                            format_func=lambda x: f"{self.config.SUPPORTED_LANGUAGES[x]} ({x})",
                            index=list(self.config.SUPPORTED_LANGUAGES.keys()).index(selected_target_info['language_code']) if selected_target_info['language_code'] in self.config.SUPPORTED_LANGUAGES else 0
                        )
                        final_language_code = manual_language
                        
                        if st.button("í™•ì¸"):
                            st.session_state.show_language_selector = False
                            st.rerun()
                    else:
                        final_language_code = selected_target_info['language_code']
                    
                    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    st.session_state.column_selection = {
                        'source_column': source_column,
                        'target_column': selected_target_info['column_name'],
                        'language_code': final_language_code
                    }
                else:
                    st.error("**ë²ˆì—­ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**")
                    st.info("Excel íŒŒì¼ì— ë²ˆì—­ëœ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    return
            else:
                st.error("**ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**")
                st.info("íŒŒì¼ì´ ì˜¬ë°”ë¥¸ Excel í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
                
        except Exception as e:
            st.error(f"**ì»¬ëŸ¼ ì •ë³´ ë¡œë“œ ì˜¤ë¥˜:** {e}")
            return
        
        st.markdown("---")
        
        # 4ë‹¨ê³„: í‰ê°€ ì‹¤í–‰
        st.markdown("### 4ë‹¨ê³„: í‰ê°€ ì‹¤í–‰")
        st.markdown("ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ì¤€ë¹„ ìƒíƒœ í™•ì¸
        ready_for_evaluation = (
            st.session_state.evaluation_engine and 
            'column_selection' in st.session_state
        )
        
        if ready_for_evaluation:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.success("í‰ê°€ ì¤€ë¹„ ì™„ë£Œ! í‰ê°€ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                st.info("ê¸°ë³¸ ì„¤ì •: ìµœëŒ€ 10ê°œ ë²ˆì—­ ìŒì„ 5ê°œì”© ë³‘ë ¬ë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
            
            with col2:
                if st.button("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", type="secondary"):
                    self.preview_data()
        else:
            missing_items = []
            if not st.session_state.evaluation_engine:
                missing_items.append("API í‚¤ ì„¤ì •")
            if 'column_selection' not in st.session_state:
                missing_items.append("ì»¬ëŸ¼ ì„ íƒ")
            st.error(f"ì¤€ë¹„ í•„ìš”: {', '.join(missing_items)}")
            return
        
        # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼
        if st.button("í‰ê°€ ì‹œì‘", type="primary", use_container_width=True):
            if not st.session_state.evaluation_engine:
                st.error("**API í‚¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”.**")
                return
            
            if 'column_selection' not in st.session_state:
                st.error("**ì»¬ëŸ¼ ì„ íƒì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
                st.info("3ë‹¨ê³„ì—ì„œ ì†ŒìŠ¤ ë° íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            # ê¸°ë³¸ ì„¤ì •ê°’ ì‚¬ìš©
            max_evaluations = 10
            max_concurrent = 5
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì • ì €ì¥
            st.session_state.max_concurrent = max_concurrent
            self.run_evaluation(max_evaluations)
    
    def preview_data(self):
        """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
        try:
            from data_processor import DataProcessor
            processor = DataProcessor()
            
            # íŒŒì¼ ê²½ë¡œ ê²°ì •
            translation_file = None
            if 'translation_file' in st.session_state:
                # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                    tmp.write(st.session_state.translation_file.getbuffer())
                    translation_file = tmp.name
            
            # ë°ì´í„° ë¡œë“œ
            df = processor.load_translation_data(translation_file)
            
            if not df.empty:
                st.success(f"ë°ì´í„° ë¡œë“œ ì„±ê³µ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
                st.dataframe(df.head(10), use_container_width=True)
                
                # ë²ˆì—­ ìŒ ì¶”ì¶œ
                pairs = processor.extract_translation_pairs(df)
                if pairs:
                    st.info(f"ì¶”ì¶œëœ ë²ˆì—­ ìŒ: {len(pairs)}ê°œ")
                    
                    # ì–¸ì–´ë³„ í†µê³„
                    stats = processor.get_language_statistics(pairs)
                    
                    stats_df = pd.DataFrame([
                        {
                            'ì–¸ì–´': stat['language_name'],
                            'ë²ˆì—­ ìŒ ìˆ˜': stat['count'],
                            'í‰ê·  ì†ŒìŠ¤ ê¸¸ì´': f"{stat['avg_source_length']:.1f}",
                            'í‰ê·  íƒ€ê²Ÿ ê¸¸ì´': f"{stat['avg_target_length']:.1f}"
                        }
                        for stat in stats.values()
                    ])
                    
                    st.dataframe(stats_df, use_container_width=True)
            else:
                st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")
    
    def run_evaluation(self, max_evaluations):
        """í‰ê°€ ì‹¤í–‰"""
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°”ì™€ ìƒíƒœ í‘œì‹œ
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
            detail_text = st.empty()
            metrics_container = st.empty()
        
        try:
            status_text.text("í‰ê°€ ì¤€ë¹„ ì¤‘...")
            detail_text.text("ì„¤ì •ì„ í™•ì¸í•˜ê³  ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.")
            
            # íŒŒì¼ ê²½ë¡œ ì„¤ì •
            translation_file = None
            
            if 'translation_file' in st.session_state:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                    tmp.write(st.session_state.translation_file.getbuffer())
                    translation_file = tmp.name
            
            progress_bar.progress(10)
            status_text.text("ë°ì´í„° ë¡œë“œ ì¤‘...")
            detail_text.text("ë²ˆì—­ ë°ì´í„°ì™€ ë©”íŠ¸ë¦­ ì •ì˜ë¥¼ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            
            # ì‚¬ìš©ì ì„ íƒ ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            column_selection = st.session_state.column_selection
            
            # ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­ê³¼ ìŠ¤ì¼€ì¼ ê°€ì ¸ì˜¤ê¸°
            custom_metrics = st.session_state.get('custom_metrics')
            custom_scale = st.session_state.get('custom_scale')
            
            progress_bar.progress(20)
            status_text.text("ë²ˆì—­ ìŒ ì¶”ì¶œ ì¤‘...")
            detail_text.text(f"ì†ŒìŠ¤: {column_selection['source_column']} â†’ íƒ€ê²Ÿ: {column_selection['target_column']}")
            
            # ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ ìœ„í•œ ì½œë°± í•¨ìˆ˜
            def update_progress(current, total, current_text=""):
                progress = 20 + int((current / total) * 70)  # 20%ì—ì„œ 90%ê¹Œì§€
                progress_bar.progress(progress)
                status_text.text(f"ë³‘ë ¬ ë²ˆì—­ í‰ê°€ ì¤‘... ({current}/{total})")
                
                # í˜„ì¬ í‰ê°€ ì¤‘ì¸ í…ìŠ¤íŠ¸ í‘œì‹œ (ì•ˆì „í•˜ê²Œ)
                if current_text:
                    display_text = current_text.replace('\n', ' ').strip()
                    if len(display_text) > 80:
                        display_text = display_text[:80] + "..."
                    detail_text.text(f"ë³‘ë ¬ ì²˜ë¦¬ ì¤‘: {display_text}")
                else:
                    detail_text.text(f"ë³‘ë ¬ í‰ê°€ ì§„í–‰ ì¤‘... ({current}/{total})")
                
                # í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ë¥ ì„ ë©”íŠ¸ë¦­ìœ¼ë¡œ í‘œì‹œ
                with metrics_container.container():
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ì§„í–‰ë¥ ", f"{(current/total)*100:.1f}%")
                    with col2:
                        st.metric("ì™„ë£Œ", current)
                    with col3:
                        st.metric("ë‚¨ì€ í‰ê°€", total - current)
                    with col4:
                        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë” ë¹ ë¥¸ ì‹œê°„ ì¶”ì •
                        max_concurrent = st.session_state.get('max_concurrent', 5)
                        time_per_eval = 3 / max_concurrent  # ë³‘ë ¬ ì²˜ë¦¬ ê³ ë ¤
                        remaining_time = int((total - current) * time_per_eval)
                        if remaining_time > 60:
                            st.metric("ì˜ˆìƒ ë‚¨ì€ ì‹œê°„", f"{remaining_time//60}ë¶„ {remaining_time%60}ì´ˆ")
                        else:
                            st.metric("ì˜ˆìƒ ë‚¨ì€ ì‹œê°„", f"{remaining_time}ì´ˆ")
            
            # í‰ê°€ ì—”ì§„ì— ì½œë°± í•¨ìˆ˜ ì „ë‹¬ì„ ìœ„í•´ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.progress_callback = update_progress
            
            # í‰ê°€ ì‹¤í–‰
            results = st.session_state.evaluation_engine.run_full_evaluation_with_columns(
                translation_file=translation_file,
                source_column=column_selection['source_column'],
                target_column=column_selection['target_column'],
                language_code=column_selection['language_code'],
                max_evaluations=max_evaluations,
                custom_metrics=custom_metrics,
                custom_scale=custom_scale,
                save_results=True
            )
            
            progress_bar.progress(95)
            status_text.text("ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
            detail_text.text("í‰ê°€ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê³  íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.")
            
            progress_bar.progress(100)
            status_text.text("í‰ê°€ ì™„ë£Œ!")
            detail_text.text("ëª¨ë“  í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ìµœì¢… ë©”íŠ¸ë¦­ í‘œì‹œ
            if 'aggregate_scores' in results and 'overall' in results['aggregate_scores']:
                with metrics_container.container():
                    st.subheader("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼")
                    metrics_data = results['aggregate_scores']['overall']
                    
                    cols = st.columns(len(metrics_data))
                    for i, (metric, data) in enumerate(metrics_data.items()):
                        with cols[i]:
                            score = data['mean']
                            st.metric(
                                label=metric.replace('/', '/\n'),
                                value=f"{score:.2f}",
                                delta=f"{self.get_quality_level(score)}"
                            )
            
            # ê²°ê³¼ ì €ì¥
            st.session_state.evaluation_results = results
            
            st.success("í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì—…ë°ì´íŠ¸ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
            if 'updated_file_path' in results.get('metadata', {}):
                updated_file_path = results['metadata']['updated_file_path']
                with open(updated_file_path, 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ ì ìˆ˜ê°€ ì±„ì›Œì§„ ì›ë³¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=f.read(),
                        file_name=os.path.basename(updated_file_path),
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            
            # ë¹ ë¥¸ ê²°ê³¼ í‘œì‹œ
            self.show_quick_results(results)
            
        except Exception as e:
            progress_bar.progress(0)
            status_text.text("ì˜¤ë¥˜ ë°œìƒ")
            detail_text.text(str(e))
            st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            # í´ë¦°ì—…
            if 'progress_callback' in st.session_state:
                del st.session_state.progress_callback
    
    def show_quick_results(self, results):
        """ë¹ ë¥¸ ê²°ê³¼ í‘œì‹œ"""
        st.markdown("### ë¹ ë¥¸ ê²°ê³¼")
        
        if 'aggregate_scores' in results and 'overall' in results['aggregate_scores']:
            metrics_data = results['aggregate_scores']['overall']
            
            # ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ í‘œì‹œ
            cols = st.columns(len(metrics_data))
            
            for i, (metric, data) in enumerate(metrics_data.items()):
                with cols[i]:
                    score = data['mean']
                    st.metric(
                        label=metric,
                        value=f"{score:.2f}",
                        delta=f"({self.get_quality_level(score)})"
                    )
        
        # ì–¸ì–´ë³„ ë¹„êµ
        if ('detailed_results' in results and 
            'language_comparison' in results['detailed_results']):
            
            st.markdown("#### ì–¸ì–´ë³„ ì „ì²´ ì ìˆ˜")
            
            lang_data = results['detailed_results']['language_comparison']
            lang_df = pd.DataFrame([
                {
                    'ì–¸ì–´': data['language_name'],
                    'í‰ê·  ì ìˆ˜': f"{data['average_overall_score']:.2f}",
                    'í’ˆì§ˆ ìˆ˜ì¤€': data['quality_level'],
                    'í‰ê°€ ê°œìˆ˜': data['evaluation_count']
                }
                for data in lang_data.values()
            ])
            
            st.dataframe(lang_df, use_container_width=True)
    def detailed_results_tab(self):
        """ìƒì„¸ ê²°ê³¼ íƒ­"""
        st.header("ìƒì„¸ í‰ê°€ ê²°ê³¼")
        
        if st.session_state.evaluation_results is None:
            st.info("ë¨¼ì € í‰ê°€ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        results = st.session_state.evaluation_results
        
        # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
        if 'evaluation_results' in results:
            st.subheader("ê°œë³„ í‰ê°€ ê²°ê³¼")
            
            # í•„í„°ë§ ì˜µì…˜
            col1, col2 = st.columns(2)
            
            with col1:
                # ì–¸ì–´ í•„í„°
                available_languages = set()
                for result in results['evaluation_results']:
                    if 'language_name' in result:
                        available_languages.add(result['language_name'])
                
                selected_languages = st.multiselect(
                    "ì–¸ì–´ í•„í„°",
                    options=list(available_languages),
                    default=list(available_languages)
                )
            
            with col2:
                # ì ìˆ˜ ë²”ìœ„ í•„í„°
                score_range = st.slider(
                    "ì „ì²´ ì ìˆ˜ ë²”ìœ„",
                    min_value=1.0,
                    max_value=5.0,
                    value=(1.0, 5.0),
                    step=0.1
                )
            
            # í•„í„°ë§ëœ ê²°ê³¼ í‘œì‹œ
            filtered_results = []
            
            for result in results['evaluation_results']:
                if ('language_name' in result and 
                    result['language_name'] in selected_languages and
                    'evaluation' in result and 
                    'Overall' in result['evaluation']):
                    
                    overall_score = result['evaluation']['Overall'].get('score', 0)
                    if score_range[0] <= overall_score <= score_range[1]:
                        filtered_results.append(result)
            
            # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
            if filtered_results:
                table_data = []
                
                for result in filtered_results[:100]:  # ìµœëŒ€ 100ê°œë§Œ í‘œì‹œ
                    row = {
                        'ID': result.get('translation_id', ''),
                        'ì–¸ì–´': result.get('language_name', ''),
                        'ì†ŒìŠ¤ í…ìŠ¤íŠ¸': result.get('source_text', '')[:100] + '...',
                        'ë²ˆì—­ í…ìŠ¤íŠ¸': result.get('target_text', '')[:100] + '...'
                    }
                    
                    # ë©”íŠ¸ë¦­ ì ìˆ˜ ì¶”ê°€
                    if 'evaluation' in result:
                        for metric in ['Accuracy', 'Omission/Addition', 'Compliance', 'Fluency', 'Overall']:
                            if metric in result['evaluation']:
                                row[metric] = result['evaluation'][metric].get('score', 0)
                    
                    table_data.append(row)
                
                df = pd.DataFrame(table_data)
                st.dataframe(df, use_container_width=True)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv = df.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.info("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        st.subheader("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        if st.button("ğŸ“¦ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (JSON)"):
            json_str = json.dumps(results, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=json_str,
                file_name=f"mt_eval_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    def metrics_settings_tab(self):
        """ë©”íŠ¸ë¦­ ë° ìŠ¤ì¼€ì¼ ì„¤ì • íƒ­"""
        st.header("í‰ê°€ ë©”íŠ¸ë¦­ ë° ìŠ¤ì¼€ì¼ ì„¤ì •")
        
        # í˜„ì¬ ì„¤ì • ë¡œë“œ
        if 'custom_metrics' not in st.session_state:
            st.session_state.custom_metrics = self.config.EVALUATION_METRICS.copy()
        
        if 'custom_scale' not in st.session_state:
            st.session_state.custom_scale = self.config.EVALUATION_SCALE.copy()
        
        # ë©”íŠ¸ë¦­ ì„¤ì • ì„¹ì…˜
        st.subheader("ğŸ“ í‰ê°€ ë©”íŠ¸ë¦­ ì •ì˜")
        st.markdown("ê° ë©”íŠ¸ë¦­ì˜ ì •ì˜ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        metrics_updated = False
        
        for metric, current_definition in st.session_state.custom_metrics.items():
            with st.expander(f"{metric} ì„¤ì •"):
                new_definition = st.text_area(
                    f"{metric} ì •ì˜",
                    value=current_definition,
                    height=100,
                    key=f"metric_{metric}"
                )
                
                if new_definition != current_definition:
                    st.session_state.custom_metrics[metric] = new_definition
                    metrics_updated = True
        
        # ìŠ¤ì¼€ì¼ ì„¤ì • ì„¹ì…˜
        st.subheader("ğŸ“Š í‰ê°€ ìŠ¤ì¼€ì¼ ì •ì˜")
        st.markdown("ê° ì ìˆ˜ë³„ ê¸°ì¤€ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        scale_updated = False
        
        for score, current_definition in st.session_state.custom_scale.items():
            with st.expander(f"{score}ì  ê¸°ì¤€ ì„¤ì •"):
                new_definition = st.text_area(
                    f"{score}ì  ì •ì˜",
                    value=current_definition,
                    height=80,
                    key=f"scale_{score}"
                )
                
                if new_definition != current_definition:
                    st.session_state.custom_scale[score] = new_definition
                    scale_updated = True
        
        # ì•¡ì…˜ ë²„íŠ¼ë“¤
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¦¬ì…‹"):
                st.session_state.custom_metrics = self.config.EVALUATION_METRICS.copy()
                st.session_state.custom_scale = self.config.EVALUATION_SCALE.copy()
                st.success("ì„¤ì •ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
        
        with col2:
            if st.button("ğŸ’¾ ì„¤ì • ì €ì¥"):
                self.save_custom_settings()
                st.success("ì‚¬ìš©ì ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with col3:
            if st.button("ğŸ“‚ ì„¤ì • ë‚´ë³´ë‚´ê¸°"):
                self.export_settings()
        
        # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        st.subheader("ğŸ“¥ ì„¤ì • ê°€ì ¸ì˜¤ê¸°")
        st.markdown("ì´ì „ì— ë‚´ë³´ë‚¸ ì„¤ì • íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë©”íŠ¸ë¦­ê³¼ ìŠ¤ì¼€ì¼ ì •ì˜ë¥¼ ë³µì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        uploaded_settings = st.file_uploader(
            "ì„¤ì • íŒŒì¼ ì—…ë¡œë“œ (JSON)",
            type=['json'],
            help="MT-Eval Proì—ì„œ ë‚´ë³´ë‚¸ ì„¤ì • íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.",
            key="settings_uploader"
        )
        
        if uploaded_settings is not None:
            try:
                import json
                settings_data = json.loads(uploaded_settings.read().decode('utf-8'))
                
                # ì„¤ì • íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
                if 'metrics' in settings_data and 'scale' in settings_data:
                    # ë©”íŠ¸ë¦­ ê²€ì¦
                    required_metrics = ['Accuracy', 'Omission/Addition', 'Compliance', 'Fluency', 'Overall']
                    if all(metric in settings_data['metrics'] for metric in required_metrics):
                        # ìŠ¤ì¼€ì¼ ê²€ì¦
                        required_scales = [1, 2, 3, 4, 5]
                        if all(scale in settings_data['scale'] for scale in required_scales):
                            st.session_state.custom_metrics = settings_data['metrics']
                            st.session_state.custom_scale = settings_data['scale']
                            
                            # ì„±ê³µ ë©”ì‹œì§€ì™€ ë¯¸ë¦¬ë³´ê¸°
                            st.success("ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™€ì¡ŒìŠµë‹ˆë‹¤!")
                            
                            with st.expander("ê°€ì ¸ì˜¨ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°"):
                                st.write("**ë©”íŠ¸ë¦­ ì •ì˜:**")
                                for metric, definition in settings_data['metrics'].items():
                                    st.write(f"â€¢ {metric}: {definition[:100]}...")
                                
                                st.write("**ìŠ¤ì¼€ì¼ ì •ì˜:**")
                                for score, definition in settings_data['scale'].items():
                                    st.write(f"â€¢ {score}ì : {definition[:80]}...")
                            
                            st.rerun()
                        else:
                            st.error("ì„¤ì • íŒŒì¼ì— í•„ìˆ˜ ìŠ¤ì¼€ì¼ ì •ì˜(1-5ì )ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ì„¤ì • íŒŒì¼ì— í•„ìˆ˜ ë©”íŠ¸ë¦­ ì •ì˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì„¤ì • íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. 'metrics'ì™€ 'scale' ì„¹ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    
            except json.JSONDecodeError:
                st.error("ìœ íš¨í•˜ì§€ ì•Šì€ JSON íŒŒì¼ì…ë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # í˜„ì¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°
        if st.checkbox("í˜„ì¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°"):
            st.subheader("í˜„ì¬ ë©”íŠ¸ë¦­ ì„¤ì •")
            for metric, definition in st.session_state.custom_metrics.items():
                st.markdown(f"**{metric}**: {definition}")
            
            st.subheader("í˜„ì¬ ìŠ¤ì¼€ì¼ ì„¤ì •")
            for score, definition in st.session_state.custom_scale.items():
                st.markdown(f"**{score}ì **: {definition}")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.subheader("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        
        with st.expander("ì§€ì› ì–¸ì–´"):
            lang_df = pd.DataFrame([
                {'ì–¸ì–´ ì½”ë“œ': code, 'ì–¸ì–´ëª…': name}
                for code, name in self.config.SUPPORTED_LANGUAGES.items()
            ])
            st.dataframe(lang_df, use_container_width=True)
        
        with st.expander("ì‚¬ìš©ë²• ì•ˆë‚´"):
            st.markdown("""
            **ë©”íŠ¸ë¦­ ì„¤ì • ì‚¬ìš©ë²•:**
            1. ìœ„ì˜ ë©”íŠ¸ë¦­ ì •ì˜ì™€ ìŠ¤ì¼€ì¼ ì •ì˜ë¥¼ ì›í•˜ëŠ” ëŒ€ë¡œ ìˆ˜ì •
            2. "ì„¤ì • ì €ì¥" ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë³€ê²½ì‚¬í•­ ì €ì¥
            3. "í‰ê°€ ì‹¤í–‰" íƒ­ì—ì„œ ë²ˆì—­ í‰ê°€ ì‹œ ìë™ìœ¼ë¡œ ì‚¬ìš©ì ì„¤ì • ì ìš©
            
            **ì„¤ì • ê³µìœ :**
            - "ì„¤ì • ë‚´ë³´ë‚´ê¸°" ë²„íŠ¼ìœ¼ë¡œ í˜„ì¬ ì„¤ì •ì„ JSON íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
            - ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œ "ì„¤ì • ê°€ì ¸ì˜¤ê¸°"ë¡œ ë™ì¼í•œ ì„¤ì • ì‚¬ìš© ê°€ëŠ¥
            
            **ì£¼ì˜ì‚¬í•­:**
            - ë©”íŠ¸ë¦­ ì´ë¦„(Accuracy, Omission/Addition ë“±)ì€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”
            - ìŠ¤ì¼€ì¼ì€ ë°˜ë“œì‹œ 1-5ì  ì²´ê³„ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤
            """)
    
    def save_custom_settings(self):
        """ì‚¬ìš©ì ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            settings_data = {
                'metrics': st.session_state.custom_metrics,
                'scale': st.session_state.custom_scale,
                'timestamp': datetime.now().isoformat()
            }
            
            # ì„¤ì • ë””ë ‰í† ë¦¬ ìƒì„±
            settings_dir = "user_settings"
            if not os.path.exists(settings_dir):
                os.makedirs(settings_dir)
            
            # ì„¤ì • íŒŒì¼ ì €ì¥
            settings_path = os.path.join(settings_dir, "custom_metrics.json")
            with open(settings_path, 'w', encoding='utf-8') as f:
                json.dump(settings_data, f, ensure_ascii=False, indent=2)
            
            return settings_path
        except Exception as e:
            st.error(f"ì„¤ì • ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def export_settings(self):
        """í˜„ì¬ ì„¤ì •ì„ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            settings_data = {
                'metrics': st.session_state.custom_metrics,
                'scale': st.session_state.custom_scale,
                'exported_at': datetime.now().isoformat(),
                'version': '1.0'
            }
            
            settings_json = json.dumps(settings_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="ğŸ“¥ ì„¤ì • íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=settings_json,
                file_name=f"mt_eval_settings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        except Exception as e:
            st.error(f"ì„¤ì • ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
    

    
    def get_quality_level(self, score):
        """ì ìˆ˜ë¥¼ í’ˆì§ˆ ìˆ˜ì¤€ìœ¼ë¡œ ë³€í™˜"""
        if score >= 4.5:
            return "ìš°ìˆ˜"
        elif score >= 3.5:
            return "ì–‘í˜¸"
        elif score >= 2.5:
            return "ë³´í†µ"
        elif score >= 1.5:
            return "ë¯¸í¡"
        else:
            return "ë§¤ìš° ë¯¸í¡"


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    app = MTEvalProApp()
    app.main()


if __name__ == "__main__":
    main() 